{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's Up Zoc?\n",
    "What's Up Zoc is an end-to-end product to help users find a better doctor.\n",
    "## Preprocessing of reviews\n",
    "After scraping the data and storing them in a csv file, the reviews are preprocessed to be feeded into LDA topic modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doctor</th>\n",
       "      <th>doctor_type</th>\n",
       "      <th>name</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dr. Paul Chrzanowski, MD</td>\n",
       "      <td>Pulmonologist</td>\n",
       "      <td>Norma R., verified patient</td>\n",
       "      <td>5,5,5</td>\n",
       "      <td>Excellent and caring doctor. He is very helpfu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dr. Paul Chrzanowski, MD</td>\n",
       "      <td>Pulmonologist</td>\n",
       "      <td>Richard T., verified patient</td>\n",
       "      <td>5,5,5</td>\n",
       "      <td>Very approachable and insightful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dr. Paul Chrzanowski, MD</td>\n",
       "      <td>Pulmonologist</td>\n",
       "      <td>Julie J., verified patient</td>\n",
       "      <td>5,5,5</td>\n",
       "      <td>Great doctor! Thoughtful, kind, thorough, smart.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dr. Paul Chrzanowski, MD</td>\n",
       "      <td>Pulmonologist</td>\n",
       "      <td>Andrew U., verified patient</td>\n",
       "      <td>5,5,5</td>\n",
       "      <td>Dr. Chrzanowski is always polite and shows tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dr. Paul Chrzanowski, MD</td>\n",
       "      <td>Pulmonologist</td>\n",
       "      <td>Richard T., verified patient</td>\n",
       "      <td>5,5,5</td>\n",
       "      <td>Very good, he’s very helpful, approachable, kn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     doctor    doctor_type                          name  \\\n",
       "0  Dr. Paul Chrzanowski, MD  Pulmonologist    Norma R., verified patient   \n",
       "1  Dr. Paul Chrzanowski, MD  Pulmonologist  Richard T., verified patient   \n",
       "2  Dr. Paul Chrzanowski, MD  Pulmonologist    Julie J., verified patient   \n",
       "3  Dr. Paul Chrzanowski, MD  Pulmonologist   Andrew U., verified patient   \n",
       "4  Dr. Paul Chrzanowski, MD  Pulmonologist  Richard T., verified patient   \n",
       "\n",
       "  rating                                               text  \n",
       "0  5,5,5  Excellent and caring doctor. He is very helpfu...  \n",
       "1  5,5,5                   Very approachable and insightful  \n",
       "2  5,5,5   Great doctor! Thoughtful, kind, thorough, smart.  \n",
       "3  5,5,5  Dr. Chrzanowski is always polite and shows tha...  \n",
       "4  5,5,5  Very good, he’s very helpful, approachable, kn...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the scraped data\n",
    "df = pd.read_pickle(\"df_cleaned.pkl\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break down the reviews into sentences\n",
    "from nltk.tokenize import sent_tokenize\n",
    "sent_list = []\n",
    "num_revs = []\n",
    "for doc in df.doctor.unique():\n",
    "    sent_list.append(df.loc[df.doctor == doc, \"text\"].apply(lambda x: sent_tokenize(x)).values)\n",
    "    num_revs.append((doc, df.loc[df.doctor == doc, \"text\"].apply(lambda x: len(sent_tokenize(x))).values.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that the reviews are broken down into sentences, the doctor names should be associated with each sentence as opposed to each review which was the case before breaking down the reviews\n",
    "import itertools\n",
    "df_sent = pd.DataFrame(columns = [\"doctor\", \"sentences\"])\n",
    "merged = list(itertools.chain(*itertools.chain(*sent_list)))\n",
    "df_sent[\"sentences\"] = pd.Series(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for _, val in enumerate(num_revs):\n",
    "    lst.append(list(itertools.repeat(val[0], val[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = list(itertools.chain(*lst))\n",
    "df_sent[\"doctor\"] = pd.Series(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doctor</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dr. Paul Chrzanowski, MD</td>\n",
       "      <td>Excellent and caring doctor.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dr. Paul Chrzanowski, MD</td>\n",
       "      <td>He is very helpful and knowledgeable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dr. Paul Chrzanowski, MD</td>\n",
       "      <td>Very approachable and insightful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dr. Paul Chrzanowski, MD</td>\n",
       "      <td>Great doctor!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dr. Paul Chrzanowski, MD</td>\n",
       "      <td>Thoughtful, kind, thorough, smart.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     doctor                              sentences\n",
       "0  Dr. Paul Chrzanowski, MD           Excellent and caring doctor.\n",
       "1  Dr. Paul Chrzanowski, MD  He is very helpful and knowledgeable.\n",
       "2  Dr. Paul Chrzanowski, MD       Very approachable and insightful\n",
       "3  Dr. Paul Chrzanowski, MD                          Great doctor!\n",
       "4  Dr. Paul Chrzanowski, MD     Thoughtful, kind, thorough, smart."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162470, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df_sent\n",
    "# df_sent.to_pickle(\"df_sent.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Doctors' names as they will not be helpful in finding topics\n",
    "import re\n",
    "def removeDrsNames(df):\n",
    "    df[\"sent_noDrs\"] = df[\"sentences\"].apply(lambda x: re.sub(r'dr.\\s*([^\\s]+)', '', x.lower()))\n",
    "    df[\"sent_noDrs\"] = df[\"sent_noDrs\"].apply(lambda x: re.sub(r'dr\\s*([^\\s]+)', '', x.lower()))\n",
    "    df[\"sent_noDrs\"] = df[\"sent_noDrs\"].apply(lambda x: re.sub(r'doctor\\s*([^\\s]+)', '', x.lower()))\n",
    "    df[\"sent_noDrs\"] = df[\"sent_noDrs\"].apply(lambda x: re.sub(r'doc\\s*([^\\s]+)', '', x.lower()))\n",
    "    df[\"sent_noDrs\"] = df[\"sent_noDrs\"].apply(lambda x: re.sub(r'docs\\s*([^\\s]+)', '', x.lower()))\n",
    "    return df\n",
    "\n",
    "df_sent = removeDrsNames(df_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doctor</th>\n",
       "      <th>sentences</th>\n",
       "      <th>sent_noDrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dr. Paul Chrzanowski, MD</td>\n",
       "      <td>Excellent and caring doctor.</td>\n",
       "      <td>excellent and caring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dr. Paul Chrzanowski, MD</td>\n",
       "      <td>He is very helpful and knowledgeable.</td>\n",
       "      <td>he is very helpful and knowledgeable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dr. Paul Chrzanowski, MD</td>\n",
       "      <td>Very approachable and insightful</td>\n",
       "      <td>very approachable and insightful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dr. Paul Chrzanowski, MD</td>\n",
       "      <td>Great doctor!</td>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dr. Paul Chrzanowski, MD</td>\n",
       "      <td>Thoughtful, kind, thorough, smart.</td>\n",
       "      <td>thoughtful, kind, thorough, smart.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     doctor                              sentences  \\\n",
       "0  Dr. Paul Chrzanowski, MD           Excellent and caring doctor.   \n",
       "1  Dr. Paul Chrzanowski, MD  He is very helpful and knowledgeable.   \n",
       "2  Dr. Paul Chrzanowski, MD       Very approachable and insightful   \n",
       "3  Dr. Paul Chrzanowski, MD                          Great doctor!   \n",
       "4  Dr. Paul Chrzanowski, MD     Thoughtful, kind, thorough, smart.   \n",
       "\n",
       "                              sent_noDrs  \n",
       "0                  excellent and caring   \n",
       "1  he is very helpful and knowledgeable.  \n",
       "2       very approachable and insightful  \n",
       "3                                 great   \n",
       "4     thoughtful, kind, thorough, smart.  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sent.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove new line chars\n",
    "- Break sentences into words (tokenize)\n",
    "- remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "stopword_set = frozenset(nltk.corpus.stopwords.words('english'))\n",
    "def strip_newline(series):\n",
    "    return [review.replace('\\n','') for review in series]\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stopword_set] \\\n",
    "            for doc in texts]\n",
    "def bigrams(words, bi_min=15, tri_min=10):\n",
    "    bigram = gensim.models.Phrases(words, min_count = bi_min)\n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "    return bigram_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = sent_to_words(df_sent.sent_noDrs)\n",
    "words = remove_stopwords(words)\n",
    "bigram = bigrams(words)\n",
    "bigram = [bigram[review] for review in words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert the list of tokens into a series and add it to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sent[\"tokens\"] = pd.Series(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect adjectives using POS (Part of Speach taggging) and Remove them as they are not helpful in finding topics. They should be considered in the sentiment analysis step though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tags = df_sent[\"tokens\"].apply(lambda x: nltk.pos_tag(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      [(excellent, JJ), (caring, NN)]\n",
       "1                 [(helpful, NN), (knowledgeable, JJ)]\n",
       "2               [(approachable, JJ), (insightful, NN)]\n",
       "3                                        [(great, JJ)]\n",
       "4    [(thoughtful, JJ), (kind, NN), (thorough, IN),...\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove adjectives\n",
    "pos_tags = pos_tags.apply(lambda x: [item[0] for item in x if item[1] not in [\"JJ\", \"JJR\", \"JJS\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Lemmatization__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df_sent[\"lemmatized\"] = pos_tags.apply(lambda x : [lemmatizer.lemmatize(i, pos = 'v') for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doctor</th>\n",
       "      <th>sentences</th>\n",
       "      <th>sent_noDrs</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dr. Paul Chrzanowski, MD</td>\n",
       "      <td>Excellent and caring doctor.</td>\n",
       "      <td>excellent and caring</td>\n",
       "      <td>[excellent, caring]</td>\n",
       "      <td>[care]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dr. Paul Chrzanowski, MD</td>\n",
       "      <td>He is very helpful and knowledgeable.</td>\n",
       "      <td>he is very helpful and knowledgeable.</td>\n",
       "      <td>[helpful, knowledgeable]</td>\n",
       "      <td>[helpful]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dr. Paul Chrzanowski, MD</td>\n",
       "      <td>Very approachable and insightful</td>\n",
       "      <td>very approachable and insightful</td>\n",
       "      <td>[approachable, insightful]</td>\n",
       "      <td>[insightful]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dr. Paul Chrzanowski, MD</td>\n",
       "      <td>Great doctor!</td>\n",
       "      <td>great</td>\n",
       "      <td>[great]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dr. Paul Chrzanowski, MD</td>\n",
       "      <td>Thoughtful, kind, thorough, smart.</td>\n",
       "      <td>thoughtful, kind, thorough, smart.</td>\n",
       "      <td>[thoughtful, kind, thorough, smart]</td>\n",
       "      <td>[kind, thorough, smart]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     doctor                              sentences  \\\n",
       "0  Dr. Paul Chrzanowski, MD           Excellent and caring doctor.   \n",
       "1  Dr. Paul Chrzanowski, MD  He is very helpful and knowledgeable.   \n",
       "2  Dr. Paul Chrzanowski, MD       Very approachable and insightful   \n",
       "3  Dr. Paul Chrzanowski, MD                          Great doctor!   \n",
       "4  Dr. Paul Chrzanowski, MD     Thoughtful, kind, thorough, smart.   \n",
       "\n",
       "                              sent_noDrs                               tokens  \\\n",
       "0                  excellent and caring                   [excellent, caring]   \n",
       "1  he is very helpful and knowledgeable.             [helpful, knowledgeable]   \n",
       "2       very approachable and insightful           [approachable, insightful]   \n",
       "3                                 great                               [great]   \n",
       "4     thoughtful, kind, thorough, smart.  [thoughtful, kind, thorough, smart]   \n",
       "\n",
       "                lemmatized  \n",
       "0                   [care]  \n",
       "1                [helpful]  \n",
       "2             [insightful]  \n",
       "3                       []  \n",
       "4  [kind, thorough, smart]  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sent.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gensim's LDA Mallet is used for LDA topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mallet_path = '~/Desktop/mallet-2.0.8/bin/mallet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the dictionary and the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word_mallet = gensim.corpora.Dictionary(df_sent.lemmatized)\n",
    "corpus_mallet = [id2word_mallet.doc2bow(text) for text in df_sent.lemmatized]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Finding the best number of topics__\n",
    "\n",
    "using elbow method, the model with the highest coherence value is chosen as the final LDA model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        # Don't forget the set the seed.\n",
    "        model = gensim.models.wrappers.LdaMallet(mallet_path, \\\n",
    "                                                 corpus = corpus, num_topics = num_topics, \\\n",
    "                                                 id2word = dictionary, \\\n",
    "                                                random_seed = 101)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = gensim.models.CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mahsa/anaconda3/lib/python3.6/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "# start building LDA Mallet models with number of topics in the range of 2 and 20, and step size of 3.\n",
    "model_list, coherence_values = compute_coherence_values(dictionary = id2word_mallet,\\\n",
    "                                                                  corpus = corpus_mallet, \\\n",
    "                                                        texts= df_sent.lemmatized, \\\n",
    "                                                                    start=2, limit=20, step=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "limit=20; start=2; step=3;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Topics = 2  has Coherence Value of 0.1928\n",
      "Num Topics = 5  has Coherence Value of 0.3437\n",
      "Num Topics = 8  has Coherence Value of 0.3992\n",
      "Num Topics = 11  has Coherence Value of 0.3902\n",
      "Num Topics = 14  has Coherence Value of 0.4098\n",
      "Num Topics = 17  has Coherence Value of 0.3935\n"
     ]
    }
   ],
   "source": [
    "# Print the coherence scores\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between coherence values of the 8-topic model and the 14-topic model is not significant by any means. Looking at word contents of each topic for each of these models, the model with 8 number of topics provides stronger semantic similarity between the contributing words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.160*\"care\" + 0.076*\"clean\" + 0.067*\"patients\" + 0.042*\"health\" + '\n",
      "  '0.039*\"eye\" + 0.037*\"exam\" + 0.035*\"teeth\" + 0.029*\"person\" + '\n",
      "  '0.023*\"wonderful\" + 0.014*\"contact\"'),\n",
      " (1,\n",
      "  '0.170*\"explain\" + 0.132*\"time\" + 0.049*\"understand\" + 0.043*\"things\" + '\n",
      "  '0.035*\"detail\" + 0.034*\"talk\" + 0.027*\"procedure\" + 0.023*\"step\" + '\n",
      "  '0.020*\"history\" + 0.020*\"job\"'),\n",
      " (2,\n",
      "  '0.091*\"appointment\" + 0.064*\"work\" + 0.057*\"call\" + 0.051*\"back\" + '\n",
      "  '0.043*\"test\" + 0.037*\"result\" + 0.037*\"day\" + 0.029*\"schedule\" + '\n",
      "  '0.028*\"follow\" + 0.023*\"appointments\"'),\n",
      " (3,\n",
      "  '0.334*\"recommend\" + 0.233*\"highly\" + 0.035*\"practice\" + 0.030*\"experience\" '\n",
      "  '+ 0.029*\"family\" + 0.029*\"friends\" + 0.021*\"continue\" + 0.020*\"place\" + '\n",
      "  '0.015*\"dermatologist\" + 0.011*\"refer\"'),\n",
      " (4,\n",
      "  '0.268*\"time\" + 0.186*\"wait\" + 0.070*\"minutes\" + 0.040*\"room\" + '\n",
      "  '0.037*\"appointment\" + 0.029*\"long\" + 0.029*\"hour\" + 0.025*\"bite\" + '\n",
      "  '0.023*\"walk\" + 0.020*\"spend\"'),\n",
      " (5,\n",
      "  '0.168*\"office\" + 0.073*\"amaze\" + 0.068*\"professional\" + 0.068*\"love\" + '\n",
      "  '0.056*\"excellent\" + 0.048*\"service\" + 0.045*\"staff\" + 0.026*\"experience\" + '\n",
      "  '0.024*\"absolutely\" + 0.023*\"team\"'),\n",
      " (6,\n",
      "  '0.245*\"staff\" + 0.146*\"office\" + 0.123*\"friendly\" + 0.051*\"helpful\" + '\n",
      "  '0.042*\"efficient\" + 0.038*\"pleasant\" + 0.037*\"nice\" + 0.034*\"desk\" + '\n",
      "  '0.024*\"front\" + 0.023*\"super\"'),\n",
      " (7,\n",
      "  '0.071*\"back\" + 0.070*\"experience\" + 0.066*\"years\" + 0.055*\"pain\" + '\n",
      "  '0.034*\"work\" + 0.021*\"start\" + 0.018*\"months\" + 0.017*\"finally\" + '\n",
      "  '0.016*\"today\" + 0.015*\"surgery\"'),\n",
      " (8,\n",
      "  '0.132*\"kind\" + 0.106*\"patient\" + 0.101*\"manner\" + 0.091*\"extremely\" + '\n",
      "  '0.065*\"bedside\" + 0.056*\"care\" + 0.017*\"assistant\" + 0.016*\"physician\" + '\n",
      "  '0.015*\"professional\" + 0.014*\"informative\"'),\n",
      " (9,\n",
      "  '0.047*\"insurance\" + 0.047*\"check\" + 0.030*\"fill\" + 0.027*\"receptionist\" + '\n",
      "  '0.026*\"review\" + 0.025*\"zoc\" + 0.023*\"information\" + 0.018*\"pay\" + '\n",
      "  '0.016*\"end\" + 0.016*\"give\"'),\n",
      " (10,\n",
      "  '0.197*\"visit\" + 0.111*\"dentist\" + 0.108*\"find\" + 0.045*\"experience\" + '\n",
      "  '0.036*\"forward\" + 0.031*\"point\" + 0.029*\"meet\" + 0.019*\"fast\" + '\n",
      "  '0.019*\"glad\" + 0.019*\"year\"'),\n",
      " (11,\n",
      "  '0.090*\"issue\" + 0.045*\"problem\" + 0.038*\"ease\" + 0.037*\"treat\" + '\n",
      "  '0.030*\"put\" + 0.029*\"quickly\" + 0.027*\"immediately\" + 0.027*\"condition\" + '\n",
      "  '0.023*\"show\" + 0.021*\"life\"'),\n",
      " (12,\n",
      "  '0.254*\"make\" + 0.209*\"feel\" + 0.086*\"felt\" + 0.060*\"rush\" + 0.042*\"leave\" + '\n",
      "  '0.038*\"visit\" + 0.030*\"talk\" + 0.026*\"hand\" + 0.014*\"enjoy\" + 0.012*\"home\"'),\n",
      " (13,\n",
      "  '0.176*\"question\" + 0.100*\"concern\" + 0.090*\"listen\" + 0.082*\"answer\" + '\n",
      "  '0.076*\"give\" + 0.059*\"treatment\" + 0.034*\"provide\" + 0.033*\"plan\" + '\n",
      "  '0.032*\"ad\" + 0.024*\"options\"')]\n"
     ]
    }
   ],
   "source": [
    "# Select model 4 (the model with 14 number of topics) and print the topics\n",
    "from pprint import pprint\n",
    "optimal_model = model_list[4]\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.171*\"time\" + 0.105*\"question\" + 0.097*\"explain\" + 0.049*\"answer\" + '\n",
      "  '0.044*\"treatment\" + 0.029*\"patient\" + 0.028*\"understand\" + 0.024*\"things\" + '\n",
      "  '0.022*\"lot\" + 0.021*\"options\"'),\n",
      " (1,\n",
      "  '0.148*\"make\" + 0.121*\"feel\" + 0.057*\"manner\" + 0.053*\"felt\" + 0.040*\"visit\" '\n",
      "  '+ 0.037*\"bedside\" + 0.035*\"rush\" + 0.025*\"talk\" + 0.025*\"leave\" + '\n",
      "  '0.022*\"ease\"'),\n",
      " (2,\n",
      "  '0.122*\"care\" + 0.060*\"concern\" + 0.055*\"give\" + 0.053*\"listen\" + '\n",
      "  '0.052*\"issue\" + 0.038*\"patients\" + 0.026*\"problem\" + 0.025*\"patient\" + '\n",
      "  '0.024*\"health\" + 0.021*\"treat\"'),\n",
      " (3,\n",
      "  '0.178*\"office\" + 0.167*\"staff\" + 0.073*\"kind\" + 0.072*\"friendly\" + '\n",
      "  '0.048*\"professional\" + 0.040*\"extremely\" + 0.030*\"helpful\" + '\n",
      "  '0.025*\"efficient\" + 0.022*\"pleasant\" + 0.022*\"nice\"'),\n",
      " (4,\n",
      "  '0.106*\"wait\" + 0.072*\"appointment\" + 0.060*\"time\" + 0.040*\"minutes\" + '\n",
      "  '0.031*\"call\" + 0.027*\"insurance\" + 0.026*\"check\" + 0.023*\"room\" + '\n",
      "  '0.020*\"day\" + 0.017*\"fill\"'),\n",
      " (5,\n",
      "  '0.190*\"recommend\" + 0.132*\"highly\" + 0.084*\"experience\" + 0.063*\"dentist\" + '\n",
      "  '0.062*\"find\" + 0.038*\"years\" + 0.020*\"practice\" + 0.017*\"family\" + '\n",
      "  '0.016*\"friends\" + 0.012*\"continue\"'),\n",
      " (6,\n",
      "  '0.068*\"back\" + 0.056*\"work\" + 0.043*\"clean\" + 0.031*\"pain\" + 0.024*\"test\" + '\n",
      "  '0.021*\"result\" + 0.020*\"forward\" + 0.020*\"teeth\" + 0.016*\"follow\" + '\n",
      "  '0.016*\"meet\"'),\n",
      " (7,\n",
      "  '0.097*\"visit\" + 0.042*\"amaze\" + 0.039*\"love\" + 0.032*\"excellent\" + '\n",
      "  '0.027*\"service\" + 0.022*\"eye\" + 0.021*\"exam\" + 0.017*\"point\" + '\n",
      "  '0.015*\"person\" + 0.015*\"review\"')]\n"
     ]
    }
   ],
   "source": [
    "# Select model 2 (the model with 8 number of topics) and print the topics\n",
    "optimal_model = model_list[2]\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 8-topic model is chosen as the final LDA model. Let's find the dominant topic for each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mahsa/anaconda3/lib/python3.6/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.1422</td>\n",
       "      <td>care, concern, give, listen, issue, patients, ...</td>\n",
       "      <td>[care]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.1422</td>\n",
       "      <td>office, staff, kind, friendly, professional, e...</td>\n",
       "      <td>[helpful]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.1422</td>\n",
       "      <td>visit, amaze, love, excellent, service, eye, e...</td>\n",
       "      <td>[insightful]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>time, question, explain, answer, treatment, pa...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>care, concern, give, listen, issue, patients, ...</td>\n",
       "      <td>[kind, thorough, smart]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.1528</td>\n",
       "      <td>care, concern, give, listen, issue, patients, ...</td>\n",
       "      <td>[always, polite, show, truly, care, patients]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1830</td>\n",
       "      <td>time, question, explain, answer, treatment, pa...</td>\n",
       "      <td>[make, feel, ask, question, ensure, explain, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.1548</td>\n",
       "      <td>back, work, clean, pain, test, result, forward...</td>\n",
       "      <td>[also, take, care, things, like, blood, sample]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1384</td>\n",
       "      <td>recommend, highly, experience, dentist, find, ...</td>\n",
       "      <td>[thankful, stumble, practice, neighborhood]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.1422</td>\n",
       "      <td>office, staff, kind, friendly, professional, e...</td>\n",
       "      <td>[helpful, etc]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0            0             2.0              0.1422   \n",
       "1            1             3.0              0.1422   \n",
       "2            2             7.0              0.1422   \n",
       "3            3             0.0              0.1250   \n",
       "4            4             2.0              0.1394   \n",
       "5            5             2.0              0.1528   \n",
       "6            6             0.0              0.1830   \n",
       "7            7             6.0              0.1548   \n",
       "8            8             5.0              0.1384   \n",
       "9            9             3.0              0.1422   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  care, concern, give, listen, issue, patients, ...   \n",
       "1  office, staff, kind, friendly, professional, e...   \n",
       "2  visit, amaze, love, excellent, service, eye, e...   \n",
       "3  time, question, explain, answer, treatment, pa...   \n",
       "4  care, concern, give, listen, issue, patients, ...   \n",
       "5  care, concern, give, listen, issue, patients, ...   \n",
       "6  time, question, explain, answer, treatment, pa...   \n",
       "7  back, work, clean, pain, test, result, forward...   \n",
       "8  recommend, highly, experience, dentist, find, ...   \n",
       "9  office, staff, kind, friendly, professional, e...   \n",
       "\n",
       "                                                Text  \n",
       "0                                             [care]  \n",
       "1                                          [helpful]  \n",
       "2                                       [insightful]  \n",
       "3                                                 []  \n",
       "4                            [kind, thorough, smart]  \n",
       "5      [always, polite, show, truly, care, patients]  \n",
       "6  [make, feel, ask, question, ensure, explain, t...  \n",
       "7    [also, take, care, things, like, blood, sample]  \n",
       "8        [thankful, stumble, practice, neighborhood]  \n",
       "9                                     [helpful, etc]  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_topics_sentences(ldamodel, corpus, texts):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=corpus_mallet, texts = df_sent.lemmatized)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "# Show\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final state of all the dataframes up to this point\n",
    "# df_dominant_topic.to_pickle(\"df_dominant_topic.pkl\")\n",
    "# df_sent.to_pickle(\"df_sent_lemmatized.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_dominant_topic = pd.read_pickle(\"df_dominant_topic.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing sentences with 100/8 percentage of contribution as the topic contribution is equal for all the topics, and hence no dominant topic can be detected for such sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topicScores = df_sent.loc[df_dominant_topic[\"Topic_Perc_Contrib\"] > (100/8/100)]\n",
    "df_dominant_topic = df_dominant_topic[df_dominant_topic[\"Topic_Perc_Contrib\"] > 100/8/100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doctor</th>\n",
       "      <th>sentences</th>\n",
       "      <th>sent_noDrs</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dr. Paul Chrzanowski, MD</td>\n",
       "      <td>Excellent and caring doctor.</td>\n",
       "      <td>excellent and caring</td>\n",
       "      <td>[excellent, caring]</td>\n",
       "      <td>[care]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dr. Paul Chrzanowski, MD</td>\n",
       "      <td>He is very helpful and knowledgeable.</td>\n",
       "      <td>he is very helpful and knowledgeable.</td>\n",
       "      <td>[helpful, knowledgeable]</td>\n",
       "      <td>[helpful]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dr. Paul Chrzanowski, MD</td>\n",
       "      <td>Very approachable and insightful</td>\n",
       "      <td>very approachable and insightful</td>\n",
       "      <td>[approachable, insightful]</td>\n",
       "      <td>[insightful]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dr. Paul Chrzanowski, MD</td>\n",
       "      <td>Thoughtful, kind, thorough, smart.</td>\n",
       "      <td>thoughtful, kind, thorough, smart.</td>\n",
       "      <td>[thoughtful, kind, thorough, smart]</td>\n",
       "      <td>[kind, thorough, smart]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dr. Paul Chrzanowski, MD</td>\n",
       "      <td>Dr. Chrzanowski is always polite and shows tha...</td>\n",
       "      <td>is always polite and shows that he truly care...</td>\n",
       "      <td>[always, polite, shows, truly, cares, patients]</td>\n",
       "      <td>[always, polite, show, truly, care, patients]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     doctor  \\\n",
       "0  Dr. Paul Chrzanowski, MD   \n",
       "1  Dr. Paul Chrzanowski, MD   \n",
       "2  Dr. Paul Chrzanowski, MD   \n",
       "4  Dr. Paul Chrzanowski, MD   \n",
       "5  Dr. Paul Chrzanowski, MD   \n",
       "\n",
       "                                           sentences  \\\n",
       "0                       Excellent and caring doctor.   \n",
       "1              He is very helpful and knowledgeable.   \n",
       "2                   Very approachable and insightful   \n",
       "4                 Thoughtful, kind, thorough, smart.   \n",
       "5  Dr. Chrzanowski is always polite and shows tha...   \n",
       "\n",
       "                                          sent_noDrs  \\\n",
       "0                              excellent and caring    \n",
       "1              he is very helpful and knowledgeable.   \n",
       "2                   very approachable and insightful   \n",
       "4                 thoughtful, kind, thorough, smart.   \n",
       "5   is always polite and shows that he truly care...   \n",
       "\n",
       "                                            tokens  \\\n",
       "0                              [excellent, caring]   \n",
       "1                         [helpful, knowledgeable]   \n",
       "2                       [approachable, insightful]   \n",
       "4              [thoughtful, kind, thorough, smart]   \n",
       "5  [always, polite, shows, truly, cares, patients]   \n",
       "\n",
       "                                      lemmatized  \n",
       "0                                         [care]  \n",
       "1                                      [helpful]  \n",
       "2                                   [insightful]  \n",
       "4                        [kind, thorough, smart]  \n",
       "5  [always, polite, show, truly, care, patients]  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topicScores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.1422</td>\n",
       "      <td>care, concern, give, listen, issue, patients, ...</td>\n",
       "      <td>[care]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.1422</td>\n",
       "      <td>office, staff, kind, friendly, professional, e...</td>\n",
       "      <td>[helpful]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.1422</td>\n",
       "      <td>visit, amaze, love, excellent, service, eye, e...</td>\n",
       "      <td>[insightful]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>care, concern, give, listen, issue, patients, ...</td>\n",
       "      <td>[kind, thorough, smart]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.1528</td>\n",
       "      <td>care, concern, give, listen, issue, patients, ...</td>\n",
       "      <td>[always, polite, show, truly, care, patients]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0            0             2.0              0.1422   \n",
       "1            1             3.0              0.1422   \n",
       "2            2             7.0              0.1422   \n",
       "4            4             2.0              0.1394   \n",
       "5            5             2.0              0.1528   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  care, concern, give, listen, issue, patients, ...   \n",
       "1  office, staff, kind, friendly, professional, e...   \n",
       "2  visit, amaze, love, excellent, service, eye, e...   \n",
       "4  care, concern, give, listen, issue, patients, ...   \n",
       "5  care, concern, give, listen, issue, patients, ...   \n",
       "\n",
       "                                            Text  \n",
       "0                                         [care]  \n",
       "1                                      [helpful]  \n",
       "2                                   [insightful]  \n",
       "4                        [kind, thorough, smart]  \n",
       "5  [always, polite, show, truly, care, patients]  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dominant_topic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "Now that we have the dominant topic per sentence, we can find most positive and negative sentences per topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using NLTK's Vader sentiment analysis tool\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "df_dominant_topic[[\"neg\", \"neu\", \"pos\", \"compound\"]]= df_topicScores[\"sentences\"].apply(lambda x: sid.polarity_scores(x)).apply(pd.Series)\n",
    "df_dominant_topic[\"sentences\"] = df_topicScores[\"sentences\"]\n",
    "df_dominant_topic[\"doctor\"] = df_topicScores[\"doctor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>sentences</th>\n",
       "      <th>doctor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.1422</td>\n",
       "      <td>care, concern, give, listen, issue, patients, ...</td>\n",
       "      <td>[care]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.7845</td>\n",
       "      <td>Excellent and caring doctor.</td>\n",
       "      <td>Dr. Paul Chrzanowski, MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.1422</td>\n",
       "      <td>office, staff, kind, friendly, professional, e...</td>\n",
       "      <td>[helpful]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.4754</td>\n",
       "      <td>He is very helpful and knowledgeable.</td>\n",
       "      <td>Dr. Paul Chrzanowski, MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.1422</td>\n",
       "      <td>visit, amaze, love, excellent, service, eye, e...</td>\n",
       "      <td>[insightful]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Very approachable and insightful</td>\n",
       "      <td>Dr. Paul Chrzanowski, MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>care, concern, give, listen, issue, patients, ...</td>\n",
       "      <td>[kind, thorough, smart]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.8271</td>\n",
       "      <td>Thoughtful, kind, thorough, smart.</td>\n",
       "      <td>Dr. Paul Chrzanowski, MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.1528</td>\n",
       "      <td>care, concern, give, listen, issue, patients, ...</td>\n",
       "      <td>[always, polite, show, truly, care, patients]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.7096</td>\n",
       "      <td>Dr. Chrzanowski is always polite and shows tha...</td>\n",
       "      <td>Dr. Paul Chrzanowski, MD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0            0             2.0              0.1422   \n",
       "1            1             3.0              0.1422   \n",
       "2            2             7.0              0.1422   \n",
       "4            4             2.0              0.1394   \n",
       "5            5             2.0              0.1528   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  care, concern, give, listen, issue, patients, ...   \n",
       "1  office, staff, kind, friendly, professional, e...   \n",
       "2  visit, amaze, love, excellent, service, eye, e...   \n",
       "4  care, concern, give, listen, issue, patients, ...   \n",
       "5  care, concern, give, listen, issue, patients, ...   \n",
       "\n",
       "                                            Text  neg    neu    pos  compound  \\\n",
       "0                                         [care]  0.0  0.225  0.775    0.7845   \n",
       "1                                      [helpful]  0.0  0.618  0.382    0.4754   \n",
       "2                                   [insightful]  0.0  1.000  0.000    0.0000   \n",
       "4                        [kind, thorough, smart]  0.0  0.103  0.897    0.8271   \n",
       "5  [always, polite, show, truly, care, patients]  0.0  0.670  0.330    0.7096   \n",
       "\n",
       "                                           sentences                    doctor  \n",
       "0                       Excellent and caring doctor.  Dr. Paul Chrzanowski, MD  \n",
       "1              He is very helpful and knowledgeable.  Dr. Paul Chrzanowski, MD  \n",
       "2                   Very approachable and insightful  Dr. Paul Chrzanowski, MD  \n",
       "4                 Thoughtful, kind, thorough, smart.  Dr. Paul Chrzanowski, MD  \n",
       "5  Dr. Chrzanowski is always polite and shows tha...  Dr. Paul Chrzanowski, MD  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dominant_topic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ Retrieving 3 most positive and 3 most negative sentences with respect to each topic __\n",
    "\n",
    "Extracting the top 3 positive and negative sentences from each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_topicScores[\"dominant_topic\"] = df_dominant_topic[\"Dominant_Topic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mahsa/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n"
     ]
    }
   ],
   "source": [
    "WT_top3pos = pd.DataFrame()\n",
    "for i in df_topicScores.doctor.unique():\n",
    "    WT_top3pos = pd.concat([WT_top3pos, df_dominant_topic.loc[df_dominant_topic.loc[(df_dominant_topic.Dominant_Topic == 4.0) & (df_topicScores.doctor == i) &\\\n",
    "                      (df_dominant_topic[\"compound\"] >= 0.1) & (df_dominant_topic[\"neg\"] == 0.0)]\\\n",
    "                                         .nlargest(3, 'Topic_Perc_Contrib').index, [\"doctor\", \"sentences\", \"dominant_topic\"]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doctor</th>\n",
       "      <th>sentences</th>\n",
       "      <th>dominant_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Dr. Paul Chrzanowski, MD</td>\n",
       "      <td>Dr. Chrzanowski was so nice and I was called b...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Dr. Paul Chrzanowski, MD</td>\n",
       "      <td>Dr. C is communicative, thorough, gentle and w...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Dr. Paul Chrzanowski, MD</td>\n",
       "      <td>I think this is what doctors must have been li...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>Dr. Monica Schadlow, MD</td>\n",
       "      <td>I'm fine with waiting but when I've already fi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>Dr. Monica Schadlow, MD</td>\n",
       "      <td>First, how responsive the office was when I ca...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       doctor  \\\n",
       "126  Dr. Paul Chrzanowski, MD   \n",
       "47   Dr. Paul Chrzanowski, MD   \n",
       "121  Dr. Paul Chrzanowski, MD   \n",
       "390   Dr. Monica Schadlow, MD   \n",
       "235   Dr. Monica Schadlow, MD   \n",
       "\n",
       "                                             sentences  dominant_topic  \n",
       "126  Dr. Chrzanowski was so nice and I was called b...             NaN  \n",
       "47   Dr. C is communicative, thorough, gentle and w...             NaN  \n",
       "121  I think this is what doctors must have been li...             NaN  \n",
       "390  I'm fine with waiting but when I've already fi...             NaN  \n",
       "235  First, how responsive the office was when I ca...             NaN  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WT_top3pos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT_top3neg = pd.DataFrame()\n",
    "for i in df_topicScores.doctor.unique():\n",
    "    WT_top3neg = pd.concat([WT_top3neg, df_dominant_topic.loc[df_dominant_topic.loc[(df_dominant_topic.Dominant_Topic == 4.0) & (df_topicScores.doctor == i) &\\\n",
    "                      (df_dominant_topic[\"compound\"] < 0.1) & \\\n",
    "                                                                                   (df_dominant_topic[\"neg\"] != 0.0)]\\\n",
    "                                         .nlargest(3, 'Topic_Perc_Contrib').index, [\"doctor\", \"sentences\"]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "staff_top3pos = pd.DataFrame()\n",
    "for i in df_topicScores.doctor.unique():\n",
    "    staff_top3pos = pd.concat([staff_top3pos, df_dominant_topic.loc[df_dominant_topic.loc[(df_dominant_topic.Dominant_Topic == 3.0) & (df_topicScores.doctor == i) &\\\n",
    "                      (df_dominant_topic[\"compound\"] >= 0.1) & (df_dominant_topic[\"neg\"] == 0.0)]\\\n",
    "                                         .nlargest(3, 'Topic_Perc_Contrib').index, [\"doctor\", \"sentences\"]]])\n",
    "    \n",
    "\n",
    "staff_top3neg = pd.DataFrame()\n",
    "for i in df_topicScores.doctor.unique():\n",
    "    staff_top3neg = pd.concat([staff_top3neg, df_dominant_topic.loc[df_dominant_topic.loc[(df_dominant_topic.Dominant_Topic == 3.0) & (df_topicScores.doctor == i) &\\\n",
    "                      (df_dominant_topic[\"compound\"] < 0.1) & (df_dominant_topic[\"neg\"] != 0.0)]\\\n",
    "                                                                 .nlargest(3, 'Topic_Perc_Contrib').index, [\"doctor\", \"sentences\"]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "BM_top3pos = pd.DataFrame()\n",
    "for i in df_topicScores.doctor.unique():\n",
    "    BM_top3pos = pd.concat([BM_top3pos, df_dominant_topic.loc[df_dominant_topic.loc[(df_dominant_topic.Dominant_Topic == 1.0) & (df_topicScores.doctor == i) &\\\n",
    "                      (df_dominant_topic[\"compound\"] >= 0.1) & (df_dominant_topic[\"neg\"] == 0.0)]\\\n",
    "                                         .nlargest(3, 'Topic_Perc_Contrib').index, [\"doctor\", \"sentences\"]]])\n",
    "    \n",
    "\n",
    "BM_top3neg = pd.DataFrame()\n",
    "for i in df_topicScores.doctor.unique():\n",
    "    BM_top3neg = pd.concat([BM_top3neg, df_dominant_topic.loc[df_dominant_topic.loc[(df_dominant_topic.Dominant_Topic == 1.0) & (df_topicScores.doctor == i) &\\\n",
    "                      (df_dominant_topic[\"compound\"] < 0.1) & (df_dominant_topic[\"neg\"] != 0.0)]\\\n",
    "                                                                 .nlargest(3, 'Topic_Perc_Contrib').index, [\"doctor\", \"sentences\"]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "care_top3pos = pd.DataFrame()\n",
    "for i in df_topicScores.doctor.unique():\n",
    "    care_top3pos = pd.concat([care_top3pos, df_dominant_topic.loc[df_dominant_topic.loc[(df_dominant_topic.Dominant_Topic == 2.0) & (df_topicScores.doctor == i) &\\\n",
    "                      (df_dominant_topic[\"compound\"] >= 0.1) & (df_dominant_topic[\"neg\"] == 0.0)]\\\n",
    "                                         .nlargest(3, 'Topic_Perc_Contrib').index, [\"doctor\", \"sentences\"]]])\n",
    "    \n",
    "\n",
    "care_top3neg = pd.DataFrame()\n",
    "for i in df_topicScores.doctor.unique():\n",
    "    care_top3neg = pd.concat([care_top3neg, df_dominant_topic.loc[df_dominant_topic.loc[(df_dominant_topic.Dominant_Topic == 2.0) & (df_topicScores.doctor == i) &\\\n",
    "                      (df_dominant_topic[\"compound\"] < 0.1) & (df_dominant_topic[\"neg\"] != 0.0)]\\\n",
    "                                                                 .nlargest(3, 'Topic_Perc_Contrib').index, [\"doctor\", \"sentences\"]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_top3pos = pd.DataFrame()\n",
    "for i in df_topicScores.doctor.unique():\n",
    "    resp_top3pos = pd.concat([resp_top3pos, df_dominant_topic.loc[df_dominant_topic.loc[(df_dominant_topic.Dominant_Topic == 0.0) & (df_topicScores.doctor == i) &\\\n",
    "                      (df_dominant_topic[\"compound\"] >= 0.1) & (df_dominant_topic[\"neg\"] == 0.0)]\\\n",
    "                                         .nlargest(3, 'Topic_Perc_Contrib').index, [\"doctor\", \"sentences\"]]])\n",
    "    \n",
    "\n",
    "resp_top3neg = pd.DataFrame()\n",
    "for i in df_topicScores.doctor.unique():\n",
    "    resp_top3neg = pd.concat([resp_top3neg, df_dominant_topic.loc[df_dominant_topic.loc[(df_dominant_topic.Dominant_Topic == 0.0) & (df_topicScores.doctor == i) &\\\n",
    "                      (df_dominant_topic[\"compound\"] < 0.1) & (df_dominant_topic[\"neg\"] != 0.0)]\\\n",
    "                                                                 .nlargest(3, 'Topic_Perc_Contrib').index, [\"doctor\", \"sentences\"]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the percentage of people recommending each doctor per topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mahsa/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "for i in df_topicScores.doctor.unique():\n",
    "    freq = df_dominant_topic.loc[(df_dominant_topic.doctor == i) & (df_dominant_topic.Dominant_Topic == 4.0) & \\\n",
    "                               (df_dominant_topic[\"compound\"] >= 0.05), \"compound\"]\n",
    "    total = df_dominant_topic.loc[(df_dominant_topic.doctor == i) & (df_dominant_topic.Dominant_Topic == 4.0),\\\n",
    "                                        \"compound\"]\n",
    "    WT_top3pos.loc[WT_top3pos.doctor == i, \"avg_recomm\"] = freq.count()/total.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mahsa/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "for i in df_topicScores.doctor.unique():\n",
    "    freq = df_dominant_topic.loc[(df_dominant_topic.doctor == i) & (df_dominant_topic.Dominant_Topic == 3.0) & \\\n",
    "                               (df_dominant_topic[\"compound\"] >= 0.05), \"compound\"]\n",
    "    total = df_dominant_topic.loc[(df_dominant_topic.doctor == i) & (df_dominant_topic.Dominant_Topic == 3.0),\\\n",
    "                                        \"compound\"]\n",
    "    staff_top3pos.loc[staff_top3pos.doctor == i, \"avg_recomm\"] = freq.count()/total.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mahsa/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "for i in df_topicScores.doctor.unique():\n",
    "    freq = df_dominant_topic.loc[(df_dominant_topic.doctor == i) & (df_dominant_topic.Dominant_Topic == 2.0) & \\\n",
    "                               (df_dominant_topic[\"compound\"] >= 0.05), \"compound\"]\n",
    "    total = df_dominant_topic.loc[(df_dominant_topic.doctor == i) & (df_dominant_topic.Dominant_Topic == 2.0),\\\n",
    "                                        \"compound\"]\n",
    "    care_top3pos.loc[care_top3pos.doctor == i, \"avg_recomm\"] = freq.count()/total.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mahsa/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "for i in df_topicScores.doctor.unique():\n",
    "    freq = df_dominant_topic.loc[(df_dominant_topic.doctor == i) & (df_dominant_topic.Dominant_Topic == 1.0) & \\\n",
    "                               (df_dominant_topic[\"compound\"] >= 0.05), \"compound\"]\n",
    "    total = df_dominant_topic.loc[(df_dominant_topic.doctor == i) & (df_dominant_topic.Dominant_Topic == 1.0),\\\n",
    "                                        \"compound\"]\n",
    "    BM_top3pos.loc[BM_top3pos.doctor == i, \"avg_recomm\"] = freq.count()/total.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mahsa/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "for i in df_topicScores.doctor.unique():\n",
    "    freq = df_dominant_topic.loc[(df_dominant_topic.doctor == i) & (df_dominant_topic.Dominant_Topic == 0.0) & \\\n",
    "                               (df_dominant_topic[\"compound\"] >= 0.05), \"compound\"]\n",
    "    total = df_dominant_topic.loc[(df_dominant_topic.doctor == i) & (df_dominant_topic.Dominant_Topic == 0.0),\\\n",
    "                                        \"compound\"]\n",
    "    resp_top3pos.loc[resp_top3pos.doctor == i, \"avg_recomm\"] = freq.count()/total.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all these to have access to retrieve info for Chrome Extension\n",
    "#WT_top3pos.to_pickle(\"WT_top3pos.pkl\")\n",
    "#WT_top3neg.to_pickle(\"WT_top3neg.pkl\")\n",
    "#staff_top3pos.to_pickle(\"staff_top3pos.pkl\")\n",
    "#staff_top3neg.to_pickle(\"staff_top3neg.pkl\")\n",
    "#BM_top3pos.to_pickle(\"BM_top3pos.pkl\")\n",
    "#BM_top3neg.to_pickle(\"BM_top3neg.pkl\")\n",
    "#care_top3pos.to_pickle(\"care_top3pos.pkl\")\n",
    "#care_top3neg.to_pickle(\"care_top3neg.pkl\")\n",
    "#resp_top3pos.to_pickle(\"resp_top3pos.pkl\")\n",
    "#resp_top3neg.to_pickle(\"resp_top3neg.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
